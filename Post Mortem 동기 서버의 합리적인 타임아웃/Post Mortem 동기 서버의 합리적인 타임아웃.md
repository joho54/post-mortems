# Post Mortem: 동기 서버의 합리적인 타임아웃  
  
발단  
우리가 서버 타임아웃을 600초로 잡았던 이유는 시간이 오래 걸리는 API 호출을 백엔드 서버가 요청 처리 시점에 있었기 때문이다. 특히 LLM으로 콘텐츠를 생성하는 기능은 시간이 10분 이상 걸릴 수도 있었기 때문에, 클라이언트의 요청에 “타임아웃”이라는 필연적인 실패를 띄우지 않기 위해서는 이것을 늘리는 것이 해결책이라고 생각했다. 조금이라도 동기 서버에 대한 이해가 있는 사람이라면 여기서 이미 뒷목을 잡을 것이다.   
  
동기 서버는 왜 동기인가? HTTP 응답 과정이 순서대로 일어나기 때문이다. 정글 부트캠프를 하며 CSAPP의 Provider/Consumer 서버를 구현해본적이 있다. 이 서버의 구조는 대게 임계영역으로 제한된 작업큐 앞에서 일이 없는 워커 스레드들이 대기하다가, 세마포가 해제되면 접근해서 처리할 작업을 가져간다. 그 이후로는 한 스레드가 작업을 동기적으로 처리한다.   
  
그렇다면 반대로, 비동기 서버는 왜 비동기인가? 비동기 서버에는 블로킹 워커 개념이 없다. 대신 그 자리를 스케줄링이 차지한다. 비동기 서버는 작업할 내용을 비동기 큐에 올리고, 우선순위를 결정한다. 실시간으로 작업 스케줄링이 일어나는 와중에 CPU에 처리를 맡겨 큐의 순서와 무관하게(즉 들어온 순서나, 스케줄링 된 순서에 무관하게) 먼저 끝나는 쪽이 응답으로 돌아간다. (물론 이 스케줄링은 CPU 레벨에서 일어나는 프로세스 스케줄링과는 별도다. ) 더 로우레벨로 가지 않는다면 여기까지 봐도 이해에 지장은 없어 보인다.   
  
그렇다면 이제 처음의 문제로 돌아와보자. 동기서버의 타임아웃이 의미하는 바는, 아까의 워커 스레드에게 한 작업을 처리하기까지 몇초를 허락할 것이냐를 의미한다. 10분을 주면 그 워커 스레드는 요청 하나를 가져가서 10분동안 처리할 것이다. 워커 스레드의 개수가 3개라면, 3명만 요청해도 그 서버는 10분동안 아무 응답을 처리해줄 수 없는 불능 상태가 된다. 이건 당연히 말도 안 되는 설계다.   
  
여기서 생기는 의문이 있다. 왜 동기서버를 쓰는 거지? 응답 중에 당연히 처리가 오래 걸리는 작업이 있을 수 있는데, 그 작업마다 셀러리 워커 등의 별도 인프라가 필요한 비동기 설계를 사용하는건 제법 번거로울텐데. 비동기가 알아서 작업을 스케쥴링해준다는 명확한 장점이 있다면, 동기 서버의 장점은 무엇일까? 내가 쓰면서 느낀 장점을 추려보겠다.   
  
우선, 큐 자체의 직관상이다. 공급자 소비자 문제는 꽤나 직관적인 개념이어서 하나의 요청이 처리되는 주기에 대해 이해하기가 쉽다. 머릿속에서 쉽게 그림이 그려진다. 비교적 단순한 suffocation 이슈였던 이번 사건의 경우도, 같은 장애가 비동기서버에서 발생했다면 뭐가 원인인지 가늠이 더 안 됐을 것이다. 동기 서버에서는 간단하다. “일손”이 부족하다는 메타포로 바로 이해가 된다.   
  
그리고 이 점은 어이없는 설정 값으로 한 번 느낀 바인데, 회사에 처음 온 시점부터 장고 동기 서버의 워커 스레드 수가 1로 잡혀 있었던 것을 발견했었고, 이를 AWS 마이그레이션 중에 수정한 일이다. 그 사건으로 한가지 의문이 풀린 것이, 국어 OCR 서비스 시연 중에 한 선생님이 작업을 올렸다가 서비스 전체가 먹통이 된 사건이었다. 워커 스레드 하나가 뻗으면 서비스 전체가 죽었던 것이다. 당연히 동기 서버는 워커 스레드를 최소 3개로 잡고 스레드 사망에 대응해야 한다. 이런 멀티 스레드 구조에서 오는 장점이 생각보다 어마어마하다.   
  
우선 스레드의 응답 주기를 설정해서, 일정 횟수 이상 클라이언트 응답 수행한 스레드를 죽여버릴 수 있다. 이러면 예상치 못한 메모리 누수를 원천 차단할 수 있다. 그것도 스레드라는 제법 값 싼 비용만으로 말이다. 만약 비동기 서버라면? 자세히는 모르겠지만 비동기 큐를 처리하는 메인 비동기 서버 프로세스에 메모리 누수가 쌓이면 어떤 명시적인 (그리고 꽤나 위험한) 정리 과정이 없다면 서버 프로세스 자체가 터져버릴 가능성이 있어 보인다.   
  
이러한 명시적인 분산 환경 덕분에 오토 스케일링 환경에서도 가용한 워커 스레드 수를 정확하게 계산할 수 있다는 점도 장점이다. 장고 서버 하나에 3개의 워커를 띄웠다면, 전체 스레드 수는 여기에 컨테이너 수만 곱하면 구할 수 있다. 입사 초반에 OCR 모듈을 최적화하면서, 요청에 따른 최대 메모리 점유 용량을 이 방식으로 꽤나 정확하게 계산할 수 있었고 OOM 이슈를 해결한 적이 있다. 물론, 메인 서버에서 메모리 점유율을 계산까지 해서 OOM을 막아야 하는 상황 자체가 매우 위험하고 이 정도 무거운 작업은 별도의 비동기 작업을 처리하는 셀러리 워커로 빼야 한다는 사실을 추후에 알았지만.   
아마 비동기 서버였다면 메모리 집약적인 작업에 대한 최소한의 가늠도 쉽지 않았을 것이다. 메모리 사용 영역에 명시적인 락을 걸지 않는 이상은, 어떤 작업이 어떤 순서대로 메모리 사용이라는 임계 영역에 진입할지 알 방법이 없기 때문이다.   
  
전반적으로 정리하고 보니 동기 서버의 장점을 “예측 가능성”이라고 말할 수 있겠다. 특정 문제, 특히 자원에 대한 문제가 발생했을 때 이 성질은 해결에 엄청난 도움이 된다.   
  
  
의문점: 워커 스레드가 일을 마치면, 응답을 클라이언트로 바로 내보내나 아니면 서버의 큐로 작업 내용을 올리고 그 다음 보내나?   
추측이지만 워커 스레드도 장고 메인 프로세스와 동일한 포트를 사용할테니, 바로 응답을 못할 이유는 없을 거 같다.   
  
의문점: 비동기 작업 큐에서 각 작업이 비순차적으로 처리되면, 각 작업의 진행상황은 어떻게 기록되지?  
  
#회고  
